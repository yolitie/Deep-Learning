{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorchpabatos2",
      "provenance": [],
      "authorship_tag": "ABX9TyMqQp2BAULhPWDQQy7l2m2D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yolitie/Deep-Learning/blob/main/Pytorchpabatos2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Mvft1Ox5qYU",
        "outputId": "98082fa6-f697-40ce-8287-a8648fbe08ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1., grad_fn=<PowBackward0>)\n",
            "tensor(-2.)\n"
          ]
        }
      ],
      "source": [
        "#Backpropagation\n",
        "#Chain rule, we have two operations or two functions. First, we have an input x and we apply a function and our output is y, and we apply another function and we have as an output z.\n",
        "#We want to obtain the minimum possible value of z.\n",
        "# In order to obtain dz/dx=dz/dy*dy/dx\n",
        "# 3 steps: 1) Forward pass: compute the loss.\n",
        "#          2) Compute local gradients.\n",
        "#          3) Backward pass: Compute dLoss/dWeihts using the chain rule.\n",
        "# yap= w*x         loss=(yap-y)^2= (wx-y)^2\n",
        "\n",
        "import torch\n",
        "\n",
        "x= torch.tensor(1.0)\n",
        "y= torch.tensor(2.0)\n",
        "\n",
        "w= torch.tensor(1.0, requires_grad=True) #We are interested in the gradient so we have to specify requires_grad=True\n",
        "\n",
        "#Forward pass and compute the loss\n",
        "y_hat=x*w\n",
        "loss= (y_hat-y)**2\n",
        "print(loss)\n",
        "\n",
        "#Backward pass\n",
        "\n",
        "loss.backward()\n",
        "print(w.grad)\n",
        "\n",
        "### update our weights \n",
        "### next forward and backwards\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# f= w*x\n",
        "\n",
        "# f= 2*x\n",
        "X= np.array([1,2,3,4],dtype=np.float32)\n",
        "Y= np.array([2,4,6,8], dtype=np.float32)\n",
        "\n",
        "w=0.0\n",
        "\n",
        "#Calculate our model prediction\n",
        "def forward(x):\n",
        "  return w*x\n",
        "\n",
        "#Calculate the loss, calculating it as the MSE\n",
        "def loss(y,y_predicted):\n",
        "  return ((y_predicted-y)**2).mean()\n",
        "\n",
        "#Calculate the gradient\n",
        "#MSE =1/N*(w*x-y)**2\n",
        "#dJ/dw=1/N*2x(wx-y)\n",
        "def gradient(x,y,y_predicted):\n",
        "  return np.dot(2*x,y_predicted-y).mean()\n",
        "\n",
        "print(f'Prediction before trainin: f(5)={forward(5):.3f}')\n",
        "\n",
        "#Training\n",
        "learning_rate=0.01\n",
        "n_iters=20\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  #prediction= forward pass\n",
        "  y_pred=forward(X)\n",
        "\n",
        "  #loss \n",
        "  l= loss(Y,y_pred)\n",
        "\n",
        "  #gradients\n",
        "  dw=gradient(X,Y,y_pred)\n",
        "\n",
        "  #update weights\n",
        "  w -= learning_rate*dw\n",
        "\n",
        "  if epoch % 2==0:\n",
        "    print(f'epoch {epoch+1}: w= {w:.3f}, loss= {l:.8f}')\n",
        "  \n",
        "  print(f'Prediction after the training: f(5)= {forward(5):.3f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cx63c-IqN_bY",
        "outputId": "6138fad3-0833-4f09-a68e-855ee953a612"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction before trainin: f(5)=0.000\n",
            "epoch 1: w= 1.200, loss= 30.00000000\n",
            "Prediction after the training: f(5)= 6.000\n",
            "Prediction after the training: f(5)= 8.400\n",
            "epoch 3: w= 1.872, loss= 0.76800019\n",
            "Prediction after the training: f(5)= 9.360\n",
            "Prediction after the training: f(5)= 9.744\n",
            "epoch 5: w= 1.980, loss= 0.01966083\n",
            "Prediction after the training: f(5)= 9.898\n",
            "Prediction after the training: f(5)= 9.959\n",
            "epoch 7: w= 1.997, loss= 0.00050331\n",
            "Prediction after the training: f(5)= 9.984\n",
            "Prediction after the training: f(5)= 9.993\n",
            "epoch 9: w= 1.999, loss= 0.00001288\n",
            "Prediction after the training: f(5)= 9.997\n",
            "Prediction after the training: f(5)= 9.999\n",
            "epoch 11: w= 2.000, loss= 0.00000033\n",
            "Prediction after the training: f(5)= 10.000\n",
            "Prediction after the training: f(5)= 10.000\n",
            "epoch 13: w= 2.000, loss= 0.00000001\n",
            "Prediction after the training: f(5)= 10.000\n",
            "Prediction after the training: f(5)= 10.000\n",
            "epoch 15: w= 2.000, loss= 0.00000000\n",
            "Prediction after the training: f(5)= 10.000\n",
            "Prediction after the training: f(5)= 10.000\n",
            "epoch 17: w= 2.000, loss= 0.00000000\n",
            "Prediction after the training: f(5)= 10.000\n",
            "Prediction after the training: f(5)= 10.000\n",
            "epoch 19: w= 2.000, loss= 0.00000000\n",
            "Prediction after the training: f(5)= 10.000\n",
            "Prediction after the training: f(5)= 10.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "yyLZmwngTHD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch \n",
        "\n",
        "# f= w*x\n",
        "\n",
        "# f= 2*x\n",
        "X= torch.tensor([1,2,3,4],dtype=torch.float32)\n",
        "Y= torch.tensor([2,4,6,8], dtype=torch.float32)\n",
        "\n",
        "w=torch.tensor(0.0,dtype=torch.float32, requires_grad= True )\n",
        "\n",
        "#Calculate our model prediction\n",
        "def forward(x):\n",
        "  return w*x\n",
        "\n",
        "#Calculate the loss, calculating it as the MSE\n",
        "def loss(y,y_predicted):\n",
        "  return ((y_predicted-y)**2).mean()\n",
        "\n",
        "\n",
        "\n",
        "print(f'Prediction before trainin: f(5)={forward(5):.3f}')\n",
        "\n",
        "#Training\n",
        "learning_rate=0.01\n",
        "n_iters=100\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  #prediction= forward pass\n",
        "  y_pred=forward(X)\n",
        "\n",
        "  #loss \n",
        "  l= loss(Y,y_pred)\n",
        "\n",
        "  #gradients = backward pass\n",
        "  l.backward() #dl/dw\n",
        "\n",
        "  #update weights\n",
        "  with torch.no_grad():\n",
        "    w -= learning_rate*w.grad\n",
        "  #zero gradients \n",
        "  w.grad.zero_()\n",
        "\n",
        "\n",
        "  if epoch % 10==0:\n",
        "    print(f'epoch {epoch+1}: w= {w:.3f}, loss= {l:.8f}')\n",
        "  \n",
        "print(f'Prediction after the training: f(5)= {forward(5):.3f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "144ca589-3902-4d3b-ec05-64a0496567ec",
        "id": "EheasI2uTYnE"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction before trainin: f(5)=0.000\n",
            "epoch 1: w= 0.300, loss= 30.00000000\n",
            "epoch 11: w= 1.665, loss= 1.16278565\n",
            "epoch 21: w= 1.934, loss= 0.04506890\n",
            "epoch 31: w= 1.987, loss= 0.00174685\n",
            "epoch 41: w= 1.997, loss= 0.00006770\n",
            "epoch 51: w= 1.999, loss= 0.00000262\n",
            "epoch 61: w= 2.000, loss= 0.00000010\n",
            "epoch 71: w= 2.000, loss= 0.00000000\n",
            "epoch 81: w= 2.000, loss= 0.00000000\n",
            "epoch 91: w= 2.000, loss= 0.00000000\n",
            "Prediction after the training: f(5)= 10.000\n"
          ]
        }
      ]
    }
  ]
}